% Concept1: Matrix & Vector Basics

We'll begin with the basics of linear algebra, which are rooted in a discussion about vectors and matrices.

\begin{itemize}
	\item \nameref{concept1.1}
	\item \nameref{concept1.2}
	\item \nameref{concept1.3}
	\item \nameref{concept1.4}
	\item \nameref{concept1.5}
	\item \nameref{concept1.6}
	\item \nameref{concept1.7}
	\item \nameref{concept1.8}
	\item \nameref{concept1.9}
	\item \nameref{concept1.10}
\end{itemize}

\subsection{Operations on a Single Matrix}\label{concept1.1}
For somewhat of an analogue into data science and for review's sake, we could mention Gauss-Jordan elimination (or Gaussian elimination) to solve a system of equations. Essentially a series of row operations "mimicking" algebra. We'll skip the details and any coding in this section as the solutions available with the tools we'll build throughout the sections will be much more direct and less computationally expensive.
\\

However, we should touch on number of solutions. Systems of equations can have a few different solutions:
\begin{itemize}
	\item single, unique solution
	\item no solutions
	\item infinitely many solutions
\end{itemize}

\subsection{Matrix Addition \& Subtraction}\label{concept1.2}
For matrix addition and subtraction, matrices must be the same size, and then the operation is performed on corresponding entries between the matrices.

For example, say matrices A and B have addition or subtraction performed between them to form a matrix C. All matrices will have the same mxn (rows by columns) dimensions.

\begin{equation}
	\label{eq:generic_A}
	A = \MatrixA
\end{equation}

\begin{equation}
	\label{eq:generic_B}
	B = \MatrixB
\end{equation}

\begin{equation}
	\label{eq:A+B=C}
	\MatrixA \pm \MatrixB = \MatrixC
\end{equation}

In other words...
\begin{equation}
	A \pm B = C \Longrightarrow a_{m, n} \pm b_{m, n} = c_{m, n} \: \forall m, n
\end{equation}
\\

For python, NumPy arrays will add correspondingly (element-wise), as is shown above. However, don't make the mistake of thinking lists, or lists of lists, will perform in this manner.
\\

The following are always properties for Addition, but not always true for Subtraction:
\begin{itemize}
	\item Commutative: A + B = B + A
	\item Associative: (A + B) + C = A + (B + C)
\end{itemize}


\subsection{Matrix Multiplication (Dot Product)}\label{concept1.3}
Before diving into the dot product, we'll quickly mention scalar multiplication. Suppose we have a constant c and a Matrix A, then by performing scalar multiplication of A by c will multiply each element of A by c:

\begin{equation}
	cA = \MatrixcA
\end{equation}

\begin{equation}
	cA \Longrightarrow c*a_{m, n} \: \forall m, n
\end{equation}

Now to explain multiplying a matrix by another matrix. Dimensions and order of the matrices come into play here.

\begin{itemize}
	\item Dimensions: the number of columns of the first matrix must be equal to the number of rows of the second matrix. The dimensions of the resulting matrix will be the number of rows of the first matrix by the number of columns of the second matrix.
	\item Order: A $\cdot$ B $\neq$ B $\cdot$ A
\end{itemize}

The dot product constructs a new matrix with each element being the sum of the first matrix's rows by the second matrix's columns.
\\

Recall our generic matrices A and B, but with specified labels.

\begin{equation}
	\MatrixSpecA
\end{equation}

\begin{equation}
	\MatrixSpecB
\end{equation}

Returning dimensions discussion for a dot product:
\begin{itemize}
	\item $n_a = m_b$ must be true
	\item The resulting matrix will have dimensions $m_a$ x $n_b$
\end{itemize}

An easy way to look at this is to examine the inner and outer dimensions of the matrices:

\begin{itemize}
	\item $A_{dimensions} = m_a$ x $n_a$
	\item $B_{dimensions} = m_b$ x $n_b$
	\item Dimensions side by side: ($m_a$ x $n_a$) ($m_b$ x $n_b$)
	\item Required Dimensions: Inner Pair
	\item Resulting Dimensions: Outer Pair
\end{itemize}

The resulting matrix will be of the form:
\begin{equation}
	\AdotB
\end{equation}

Python requires a NumPy command, as using straight multiplication will multiply element-wise.

Here's an example of the dot product between two 2x2 matrices:
\begin{python}
	import numpy as np
	
	A = np.array([[2, 6], [3, -1]])
	B = np.array([[-4, -2], [1, 0]])
	C = np.dot(A, B)
	
	"""
	array([[ -2,  -4],
		   [-13,  -6]])
	"""
\end{python}



\subsection{Vector Basics}\label{concept1.4}

\subsection{Standard Basis Vector (SBV)}\label{concept1.5}

\subsection{Span}\label{concept1.6}

\subsection{Linear Dependence \& Independence}\label{concept1.7}

\subsection{Linear Subspaces}\label{concept1.8}

\subsection{Spans as Subspaces}\label{concept1.9}

\subsection{Basis}\label{concept1.10}

