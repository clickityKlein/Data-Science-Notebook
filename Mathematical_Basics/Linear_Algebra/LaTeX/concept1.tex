% Concept1: Matrix & Vector Basics

We'll begin with the basics of linear algebra, which are rooted in a discussion about vectors and matrices.

\begin{itemize}
	\item \nameref{concept1.1}
	\item \nameref{concept1.2}
	\item \nameref{concept1.3}
	\item \nameref{concept1.4}
	\item \nameref{concept1.5}
	\item \nameref{concept1.6}
	\item \nameref{concept1.7}
	\item \nameref{concept1.8}
	\item \nameref{concept1.9}
	\item \nameref{concept1.10}
\end{itemize}

\subsection{Operations on a Single Matrix}\label{concept1.1}
For somewhat of an analogue into data science and for review's sake, we could mention Gauss-Jordan elimination (or Gaussian elimination) to solve a system of equations. Essentially a series of row operations "mimicking" algebra. We'll skip the details and any coding in this section as the solutions available with the tools we'll build throughout the sections will be much more direct and less computationally expensive.
\\

However, we should touch on number of solutions. Systems of equations can have a few different solutions:
\begin{itemize}
	\item single, unique solution
	\item no solutions
	\item infinitely many solutions
\end{itemize}

\subsection{Matrix Addition \& Subtraction}\label{concept1.2}
For matrix addition and subtraction, matrices must be the same size, and then the operation is performed on corresponding entries between the matrices.

For example, say matrices A and B have addition or subtraction performed between them to form a matrix C. All matrices will have the same mxn (rows by columns) dimensions.

\begin{equation}
	\label{eq:generic_A}
	A = \MatrixA
\end{equation}

\begin{equation}
	\label{eq:generic_B}
	B = \MatrixB
\end{equation}

\begin{equation}
	\label{eq:A+B=C}
	\MatrixA \pm \MatrixB = \MatrixC
\end{equation}

In other words...
\begin{equation}
	A \pm B = C \Longrightarrow a_{m, n} \pm b_{m, n} = c_{m, n} \: \forall m, n
\end{equation}
\\

For python, NumPy arrays will add correspondingly (element-wise), as is shown above. However, don't make the mistake of thinking lists, or lists of lists, will perform in this manner.
\\

The following are always properties for Addition, but not always true for Subtraction:
\begin{itemize}
	\item Commutative: A + B = B + A
	\item Associative: (A + B) + C = A + (B + C)
\end{itemize}


\subsection{Matrix Multiplication (Dot Product)}\label{concept1.3}
Before diving into the dot product, we'll quickly mention scalar multiplication. Suppose we have a constant c and a Matrix A, then by performing scalar multiplication of A by c will multiply each element of A by c:

\begin{equation}
	cA = \MatrixcA
\end{equation}

\begin{equation}
	cA \Longrightarrow c*a_{m, n} \: \forall m, n
\end{equation}

Now to explain multiplying a matrix by another matrix. Dimensions and order of the matrices come into play here.

\begin{itemize}
	\item Dimensions: the number of columns of the first matrix must be equal to the number of rows of the second matrix. The dimensions of the resulting matrix will be the number of rows of the first matrix by the number of columns of the second matrix.
	\item Order: A $\cdot$ B $\neq$ B $\cdot$ A
\end{itemize}

The dot product constructs a new matrix with each element being the sum of the first matrix's rows by the second matrix's columns.
\\

For the dot product, the matrices can obviously be different dimensions as long as the requirements are met, so we'll slightly alter our generic matrices, A and B, with more specified labels.

\begin{equation}
	\MatrixSpecA
\end{equation}

\begin{equation}
	\MatrixSpecB
\end{equation}

Returning dimensions discussion for a dot product:
\begin{itemize}
	\item $n_a = m_b$ must be true
	\item The resulting matrix will have dimensions $m_a$ x $n_b$
\end{itemize}

An easy way to look at this is to examine the inner and outer dimensions of the matrices:

\begin{itemize}
	\item $A_{dimensions} = m_a$ x $n_a$
	\item $B_{dimensions} = m_b$ x $n_b$
	\item Dimensions side by side: ($m_a$ x $n_a$) ($m_b$ x $n_b$)
	\item Required Dimensions: Inner Pair
	\item Resulting Dimensions: Outer Pair
\end{itemize}

The resulting matrix will be of the form:
\begin{equation}
	\AdotB
\end{equation}

Python requires a NumPy command, as using straight multiplication will multiply element-wise.
\\

Here's an example of the dot product between two 2x2 matrices:
\begin{python}
	import numpy as np
	
	A = np.array([[2, 6], [3, -1]])
	B = np.array([[-4, -2], [1, 0]])
	C = np.dot(A, B)
	
	"""
	array([[ -2,  -4],
		   [-13,  -6]])
	"""
\end{python}

Properties of matrix multiplication (dot product):
\begin{itemize}
	\item NOT Commutative: AB $\neq$ BA
	\item Associative: (AB)C = A(BC)
	\item Distributive: A(B $\pm$ C) = AB $\pm$ AC
	\item Zero Matrix: Any matrix multiplied by the zero matrix will return a zero matrix, but depending on order, the dimensions could change
\end{itemize}


\subsection{Vector Basics}\label{concept1.4}
A vector can be thought of as a special type of matrix in which one of it's dimensions is 1. It can be represented as a column vector (column dimension = 1), or a row vector (row dimension = 1). We can break down or describe any matrix in terms of its vectors, via rows or columns. Similarly, we can build a matrix out of a collection of same length vectors.
\\

Since a vector is a special case of a matrix, as long as dimensional requirements are met, algebraic operations (addition, subtraction, matrix multiplication) between other vectors and matrices is possible.
\\

Vectors contain two pieces of information:
\begin{itemize}
	\item Direction
	\item Magnitude (length)
\end{itemize}

Magnitude is simply the length of a vector, which can be calculated using the distance formula extended to the length of the vector.
\\

Given a vector, v, with dimensions n:
\begin{equation}
	\vec{v} = \VectorV
\end{equation}

We can calculate the magnitude as follows:
\begin{equation}
	\DistanceFormula
\end{equation}

Given we now know how to find the magnitude of a vector, we can introduce the concept of the unit vector. Every vector has a vector of magnitude 1 which points in the same direction as it, this is the unit vector.

\begin{equation}
	\UnitVector
\end{equation}

Syntactically, $\vec{u} = \hat{u}$, which represents a vector has length 1.

Calculating an example in python introduces another NumPy command (and sub-module). Introducing numpy.linalg and np.linalg.norm:
\begin{python}
	v = [1, 2, 3]
	v_magnitude = np.linalg.norm(v)
	# 3.7416573867739413
	u = v / v_magnitude
	# [0.26726124 0.53452248 0.80178373]
	u_magnitude = np.linalg.norm(u)
	# 1.0
\end{python}

\subsection{Standard Basis Vector (SBV)}\label{concept1.5}
The standard basis vectors are a set of vectors which can build every vector in their own respective n-dimensional space by scaling each one. These scaled combinations are called linear combinations.
\\

Set of standard basis vectors in $\mathbb{R}^n$:
\begin{equation}
	S = s_1, s_2, . . ., s_n = \BasisVectorsSet
\end{equation}

There are n vectors, each of which has dimension n.
\\

A linear combination can build any vector in their respective n-dimensional space:
\begin{equation}
	\VectorV = \vec{v} = v_1 \cdot s_1 + . . . + v_n \cdot s_n
\end{equation}

\subsection{Span}\label{concept1.6}


\subsection{Linear Dependence \& Independence}\label{concept1.7}

\subsection{Linear Subspaces}\label{concept1.8}

\subsection{Spans as Subspaces}\label{concept1.9}

\subsection{Basis}\label{concept1.10}

